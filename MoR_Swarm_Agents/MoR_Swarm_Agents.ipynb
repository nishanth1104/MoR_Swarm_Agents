{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KcCh-gl7TG4w"
   },
   "outputs": [],
   "source": [
    "!pip install -q transformers accelerate huggingface_hub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lvWrQZSgRSNi"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from huggingface_hub import login\n",
    "\n",
    "# Set your Hugging Face API token\n",
    "HF_API_TOKEN = \"YOUR_HUGGINGFACE_API_TOKEN\"\n",
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = HF_API_TOKEN\n",
    "login(token=HF_API_TOKEN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 453,
     "referenced_widgets": [
      "67cdc0c8afb2447594414cb4cf6429c8",
      "f9020380915d480d95f7fdf80ccd7faf",
      "f45901fa86f2440cab8987889201244e",
      "b2c2f43b8f2d4c438e69925fc4cbd0e9",
      "b0e74ecd523c4f9da865dca4cc98fb9c",
      "b1838a83cfea4e54b21b96aeb6f7be76",
      "7cdca84db8604333b477997d52944c9e",
      "c5bfdac0bbed4f4aba4f6a86888d5eba",
      "60bd75e72c514ffd9dcd33169f08b9ea",
      "d7a1d82ae3e241ef95119429e31e1717",
      "af49163cafbd49c2af67ac5aaaa6c086",
      "435535f382084421b3e2acc6acfa957c",
      "33d96c44fc2a4096843ea43cc902e2c4",
      "6f778b7dfd0b4e87b9ec0d9a60798770",
      "f3e8458056d84f04bedd79b983bfab4b",
      "c1bd32f8b5fd4116ab24b026cc2d1d73",
      "c8105a33dfdd4f42a0d0bad60e29666b",
      "13d35e91442a4b06a9cf630413705043",
      "355af256364c4dd7a20213ef7829b36b",
      "35ad59d18e4a40df8452bded82a6aff6",
      "4446239e80864b40aac4d6935189c9bd",
      "e9a71a17736748148f6dd3fe936b6118",
      "d9bf7815cd7f4d9e8c9398e9823d94fb",
      "1890dff72d6e4dde93ed4e23f91d6f1e",
      "4562fd674d4e422cac38803e96dbd139",
      "ea6a0678ae6040eca715abae2410549f",
      "c7a4495a283749c487fc1bef7b42eee4",
      "d82968d9d0f04135a6055fc090a31c93",
      "f8b5395293514e66b21923d325af1a2d",
      "f61aeeeaa4a54f60ac33bbc019728017",
      "1ea1e949f3bf43a684661d3b17b030dd",
      "602569bfb36d448da85dd5b2e8c4c155",
      "1e1a9343c6a74cb29369c7b4e5b8ed32",
      "8db3b75b6b6b4fec8a704935b79bb77b",
      "c9a2ade19bd1461fb3ee70e90a433121",
      "e54ea9e4e41f4aca855799a1774acffd",
      "9f2f7323e677495c94e9def3cb3ee183",
      "d059e2cecb5d4451a6de889ea687cc5a",
      "5681e31fb52e4c14b604d4cf828cc4cb",
      "8dd2c30caf874906998a47fda910583e",
      "19d90b3132354dccb8597146fe334942",
      "beb0ce1d021a478b8372794bf69533ed",
      "13664697ea27450793bbddeeed147155",
      "0179cbd49e0a4308b2d8107bc25bf33f",
      "406241877f134bdf9f0ab344787bb6d0",
      "4fcf18eab44f4e4390c9b355d50816af",
      "fedc54ba1abf4d17a50efba07c9fe4d7",
      "05566be0262949889dbbe515198621c0",
      "7037e3f1d16048408e213c661e2f71b0",
      "633edaefe646444fac18288fa31138cd",
      "ee0c7074ac504cab9f7db3dd613b78df",
      "68b2aecb9df143cc8e9f2bceb6a97ec6",
      "357ffbe5628f41c79b015d3027ee95de",
      "4e56c759fea34968b9dea1665326053d",
      "f5dea72db44a49b4af2741a11ffe14ab",
      "7d12694d7ea0451696d13f466bb18da1",
      "e2c24ddadfbb40ac8de42fa48863d9a2",
      "f045eef62f2d4b2cbdf10f07498e4f7a",
      "3844100c854c4eec889471474f64b8c9",
      "b21561977d6f49b08967259fe4faf523",
      "666a865ec966498bb5f913f8d6c640ce",
      "265e8353bf954441875d4e1e433e0552",
      "a5dfb531ebb341b3a570cdd658de1279",
      "d35e14ee497d403f81ce592080c1da07",
      "5a4a0ff6f5bd42519eb5de03157baa06",
      "24bea88720be41dfa2fd884b607f866c",
      "b5e685008d254f56bc41690abdd2ab79",
      "f1a5104925ea422994d4862a904f5f0e",
      "3f1b01b730e6446795b72ebf6cb90fb8",
      "e02aeb08675e4402a0be16cf7137d624",
      "153c59c030ab441cb33d7a2da6db1760",
      "5a93b372fb4346f1a45ac0a826f0cee4",
      "a22520b12cd0473ba7fcea8988fea861",
      "207d00852a4a4cfab6835d9e8b8ba173",
      "eb53c3cda07e476c935d7d94cee7cb84",
      "eeb4d03ae0f9408d968e69cb2ed129f9",
      "359b89aab5a1496a8c7879b3c5fc1e9b",
      "ca5976d7a65644b4b1d39b7bb0db1b2c",
      "07398506684648f6b56abcfd65a6599b",
      "773ee58a65344f2981b31047cebdcc7f",
      "465e748b8fad43c487cffdaaa24a9263",
      "c0c4aa1becf44a5cbba322e960c406af",
      "2da11fcd90db478183b22a5257162156",
      "5874af02ccb547649ec87100fcfa1954",
      "6a653d5d5a5f487aa0f9ec8f5d233f62",
      "e86bb59704e342cd950b09362fcddbaf",
      "d00a0f2fada2472597c20f580ccad727",
      "1012cff5755e4af0bc9c9e645d031b58",
      "af61a243bd3547a087183e640c2b5448",
      "e38627661af9459a904947f5093d8874",
      "faea1f2a7e044fb1b9fc66243f15d4de",
      "1bef155d858b48f4b3b184d69fb4c738",
      "f4fb5fcdbfdb4fa79644c673a57cb47c",
      "0efe1bde3643495980bccb5191ec38bc",
      "b938b0a7a91846c9b0d05bd5d2790d92",
      "c572545d9edd4166b4c7369ec209862f",
      "7ba88f9734264690871deb73065b351f",
      "dd84c171011a44f8a804b8d8d89216c1",
      "3f7b81f070e8494ebfdd100e79a16545",
      "b9257a35b3474eb495018882708a3a31",
      "2f558942dcaa443dbb4856ca1ba1f650",
      "2fb3c3dd4db145aa8f1b7a0965d80129",
      "0ca638660b364c9faec5bfae4366dfc8",
      "9e82442fdb33444494c3214a624c0bea",
      "7ebd9a811c024c17acb9fe214ac40c47",
      "3519eb539ba7402e8592a2e3c626a49c",
      "b503187b083740cdabb1519ae6be931c",
      "df54f015b28b48b49b0015d47022a7b2",
      "10b118428271435187b64994b4c2baf8",
      "399641ccaf18434387143613dc1a810a",
      "536a1fdd63f5407bb8fa01cad661e751",
      "c1db827377fd475c88970e299e12f4a7",
      "58cbaf5b27414339b99474d2fcc6d103",
      "86a769182b174c8bad33d573f5069f1b",
      "5222fccbc57c413cb49e7d86c23ef792",
      "fb4962ee8b6f4ea58588aa9ea9d57717",
      "8eb8227dfea842609d562fccdf29897b",
      "f570a76797344dc9a618798b87b696a0",
      "d8f67948117a4d1da524fb799d42abd8",
      "78fffba135c4497781e90b90b6398a00",
      "a6259460db32487c9b9e8db2038a4a14",
      "8ac59439791a4c078014e94de50fc2ec",
      "36ea05e0e059464cac679b963c85a26c",
      "0ad9f13b968d476299d95c51006b987e",
      "3df749db1fc34d1b8b03eded081962a4",
      "ca7089e07bfb49309cc6c5ef328c6be2",
      "7522dbf358e84c2e95bc582a7cc90b95",
      "60caff5ca53e40b28329dfdba23e85d3",
      "da092bad45f441c68e8981ef32a32c26",
      "e39ba6d8e7f046fab4246fec43804bbd",
      "1910977a7ebc453ca36af44173c3b904",
      "50f529e450de481dad31c8c59e43809f"
     ]
    },
    "id": "X9BISqOoSZO4",
    "outputId": "b54766aa-4b08-4305-ae0b-5cf2e63503e2"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "import torch\n",
    "\n",
    "model_id = \"microsoft/Phi-3-mini-4k-instruct\"\n",
    "\n",
    "# Load tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "# Define inference pipeline\n",
    "llm_pipeline = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_new_tokens=256,\n",
    "    temperature=0.7,\n",
    "    do_sample=True,\n",
    "    pad_token_id=tokenizer.eos_token_id\n",
    ")\n",
    "\n",
    "print(\"✅ Model loaded and ready!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ro6W52PLSaLr"
   },
   "outputs": [],
   "source": [
    "class BaseAgent:\n",
    "    def __init__(self, name, prompt_template):\n",
    "        self.name = name\n",
    "        self.prompt_template = prompt_template\n",
    "\n",
    "    def can_handle(self, query):\n",
    "        return any(keyword in query.lower() for keyword in self.keywords)\n",
    "\n",
    "    def handle(self, query):\n",
    "        prompt = self.prompt_template.format(query=query)\n",
    "        response = llm_pipeline(prompt, return_full_text=False)[0][\"generated_text\"]\n",
    "        return f\"[{self.name}]: {response.strip()}\"\n",
    "\n",
    "class MathAgent(BaseAgent):\n",
    "    keywords = [\"add\", \"subtract\", \"multiply\", \"divide\", \"*\", \"+\", \"-\", \"/\"]\n",
    "    def __init__(self):\n",
    "        prompt = \"You are a math expert. Solve the following:\\nQuestion: {query}\\nAnswer:\"\n",
    "        super().__init__(\"MathAgent\", prompt)\n",
    "\n",
    "class LogicAgent(BaseAgent):\n",
    "    keywords = [\"if\", \"then\", \"else\", \"logic\", \"true\", \"false\"]\n",
    "    def __init__(self):\n",
    "        prompt = \"You are a logic reasoner. Analyze:\\n{query}\\nResponse:\"\n",
    "        super().__init__(\"LogicAgent\", prompt)\n",
    "\n",
    "class LanguageAgent(BaseAgent):\n",
    "    keywords = [\"translate\", \"summarize\", \"paraphrase\"]\n",
    "    def __init__(self):\n",
    "        prompt = \"You are a language expert. Task:\\n{query}\\nResult:\"\n",
    "        super().__init__(\"LanguageAgent\", prompt)\n",
    "\n",
    "class RetrieverAgent(BaseAgent):\n",
    "    keywords = [\"who\", \"when\", \"where\", \"what\", \"which\"]\n",
    "    def __init__(self):\n",
    "        prompt = \"You are a knowledgeable assistant. Answer clearly:\\n{query}\\nAnswer:\"\n",
    "        super().__init__(\"RetrieverAgent\", prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hzvzObRQSbbo",
    "outputId": "582e6fc8-e04c-4af9-9942-03e12d0f2cfc"
   },
   "outputs": [],
   "source": [
    "class SwarmCoordinator:\n",
    "    def __init__(self, agents, recursion_limit=3):\n",
    "        self.agents = agents\n",
    "        self.recursion_limit = recursion_limit\n",
    "\n",
    "    def delegate(self, query, depth=0):\n",
    "        print(f\"[Coordinator received]: {query}\")\n",
    "        for agent in self.agents:\n",
    "            if agent.can_handle(query):\n",
    "                response = agent.handle(query)\n",
    "                print(f\"{agent.name} handled it:\\n\")\n",
    "                return response\n",
    "        if depth >= self.recursion_limit:\n",
    "            return \"⚠️ Max recursion depth reached.\"\n",
    "        return self.delegate(\"Break down: \" + query, depth + 1)\n",
    "\n",
    "# Instantiate agents and coordinator\n",
    "agents = [MathAgent(), LogicAgent(), LanguageAgent(), RetrieverAgent()]\n",
    "swarm = SwarmCoordinator(agents)\n",
    "\n",
    "# Test queries\n",
    "test_queries = [\n",
    "    \"What is the value of 7 * 6?\",\n",
    "    \"If Alice gives Bob 5 apples, and he eats 2, what is left?\",\n",
    "    \"Who was the first president of the United States?\",\n",
    "    \"Translate this to French.\",\n",
    "    \"Summarize the French Revolution.\",\n",
    "    \"Tell me something complicated.\"\n",
    "]\n",
    "\n",
    "for query in test_queries:\n",
    "    output = swarm.delegate(query)\n",
    "    print(\"\\nFinal Output:\\n\", output, \"\\n\" + \"-\"*60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e_1LpZ29ScqU"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
